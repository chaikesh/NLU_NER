{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import sklearn_crfsuite\n",
    "import nltk\n",
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('ner.txt') as f:\n",
    "    content = f.readlines()\n",
    "\n",
    "data = []\n",
    "data1 = []\n",
    "sent = []\n",
    "num_sent = 0;\n",
    "label=[]\n",
    "label_sent = []\n",
    "for content_data in content:\n",
    "    if not content_data == '\\n':\n",
    "        d1 = content_data.strip()\n",
    "        d2 = d1.split()\n",
    "        sent.append(d2[0])\n",
    "        label_sent.append(d2[1])\n",
    "    else:\n",
    "        data1.append(sent)\n",
    "        sent = nltk.pos_tag(sent)\n",
    "        data.append(sent)\n",
    "        label.append(label_sent)\n",
    "        sent = []\n",
    "        label_sent = []\n",
    "        num_sent = num_sent + 1\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(data1,min_count=1,size = 50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/chaikesh/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:3: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "/home/chaikesh/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:10: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "K = 3\n",
    "from sklearn.cluster import KMeans\n",
    "embeddings = model[model.wv.vocab]\n",
    "kmeans = KMeans(n_clusters=K)\n",
    "kmeans.fit(embeddings)\n",
    "\n",
    "\n",
    "assigned_cluster = []\n",
    "for i in range(len(data1)):\n",
    "    sent = model[data1[i]]\n",
    "    assigned_cluster.append(kmeans.predict(sent))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def word2features(sent, cluster_sent,i):\n",
    "    word = sent[i][0]\n",
    "    postag = sent[i][1]\n",
    "    cluster = cluster_sent[i]\n",
    "\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'word.lower()': word.lower(),\n",
    "        'word[-3:]': word[-3:],\n",
    "        'word[-2:]': word[-2:],\n",
    "        'word.isupper()': word.isupper(),\n",
    "        'word.istitle()': word.istitle(),\n",
    "        'word.isdigit()': word.isdigit(),\n",
    "        'postag': postag,\n",
    "        'postag[:2]': postag[:2],\n",
    "        'word2VecCluster': cluster,\n",
    "    }\n",
    "    if i > 0:\n",
    "        word1 = sent[i-1][0]\n",
    "        postag1 = sent[i-1][1]\n",
    "        features.update({\n",
    "            '-1:word.lower()': word1.lower(),\n",
    "            '-1:word.istitle()': word1.istitle(),\n",
    "            '-1:word.isupper()': word1.isupper(),\n",
    "            '-1:postag': postag1,\n",
    "            '-1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['BOS'] = True\n",
    "\n",
    "    if i < len(sent)-1:\n",
    "        word1 = sent[i+1][0]\n",
    "        postag1 = sent[i+1][1]\n",
    "        features.update({\n",
    "            '+1:word.lower()': word1.lower(),\n",
    "            '+1:word.istitle()': word1.istitle(),\n",
    "            '+1:word.isupper()': word1.isupper(),\n",
    "            '+1:postag': postag1,\n",
    "            '+1:postag[:2]': postag1[:2],\n",
    "        })\n",
    "    else:\n",
    "        features['EOS'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sent2features(sent,cluster_data):\n",
    "    return [word2features(sent,cluster_data, i) for i in range(len(sent))]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "num_train = int(np.floor(num_sent*0.7))\n",
    "num_valid = int(np.floor(num_sent*0.1))\n",
    "num_test = num_sent - num_train - num_valid\n",
    "\n",
    "idx = list(range(num_sent))\n",
    "random.shuffle(idx)\n",
    "\n",
    "train_data =[]\n",
    "train_label =[]\n",
    "valid_data = []\n",
    "valid_label = []\n",
    "test_data = []\n",
    "test_label =[]\n",
    "train_cluster = []\n",
    "valid_cluster= []\n",
    "test_cluster = []\n",
    "\n",
    "for i in range(0,num_train):\n",
    "    train_data.append(data[idx[i]])\n",
    "    train_label.append(label[idx[i]])\n",
    "    train_cluster.append(assigned_cluster[idx[i]])\n",
    "\n",
    "for i in range(num_train,num_train+num_valid):\n",
    "    valid_data.append(data[idx[i]])\n",
    "    valid_label.append(label[idx[i]])\n",
    "    valid_cluster.append(assigned_cluster[idx[i]])\n",
    "\n",
    "for i in range(num_train+num_valid,num_train+num_valid+num_test):\n",
    "    test_data.append(data[idx[i]])\n",
    "    test_label.append(label[idx[i]])\n",
    "    test_cluster.append(assigned_cluster[idx[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = []\n",
    "for i in range(len(train_data)):\n",
    "    X_train.append(sent2features(train_data[i],train_cluster[i]))\n",
    "\n",
    "Y_train = train_label\n",
    "\n",
    "\n",
    "\n",
    "X_test = []\n",
    "for i in range(len(test_data)):\n",
    "    X_test.append(sent2features(test_data[i],test_cluster[i]))\n",
    "\n",
    "Y_test = test_label\n",
    "\n",
    "crf = sklearn_crfsuite.CRF(\n",
    "    algorithm='lbfgs',\n",
    "    c1=0.1,\n",
    "    c2=0.1,\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")\n",
    "crf.fit(X_train, Y_train)\n",
    "Y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.95      0.98      0.96     11392\n",
      "          1       0.81      0.69      0.74      1049\n",
      "          2       0.77      0.56      0.65       747\n",
      "\n",
      "avg / total       0.92      0.93      0.93     13188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "\n",
    "dicts = {\"O\":0,\"D\":1,\"T\":2}\n",
    "\n",
    "Y_test_dicts = []\n",
    "Y_pred_dicts = []\n",
    "for i in range(len(test_data)):\n",
    "    Y_test_dicts  =  Y_test_dicts + ([dicts[s] for s in Y_test[i]])\n",
    "    Y_pred_dicts  = Y_pred_dicts + ([dicts[s] for s in Y_pred[i]])\n",
    "\n",
    "Y_test_dicts = np.array(Y_test_dicts)\n",
    "Y_pred_dicts = np.array(Y_pred_dicts)\n",
    "\n",
    "match_score = classification_report(Y_test_dicts,Y_pred_dicts)\n",
    "print match_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'             precision    recall  f1-score   support\\n\\n          0       0.95      0.98      0.96     11392\\n          1       0.81      0.69      0.74      1049\\n          2       0.77      0.56      0.65       747\\n\\navg / total       0.92      0.93      0.93     13188\\n'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
